{
  "Logging": {
    "LogLevel": {
      "Default": "Information",
      "Microsoft.AspNetCore": "Warning",
      "LLamaWorker": "Debug"
    }
  },
  "AllowedHosts": "*",
  // API Key
  "ApiKey": "",
  "GlobalSettings": {
    "CurrentModelIndex": 0,
    // 自动释放时间，分钟。0 表示不自动释放
    "AutoReleaseTime": 30
  },
  // LLM 服务配置
  "LLmModelSettings": [
    {
      "Name": "qwen2.5_7b",
      "Description": "通义千问 v2.5 7b instruct q5_k_m",
      "Version": "2.5",
      "WebSite": "https://github.com/QwenLM/Qwen2.5",
      // 未指定时使用默认配置
      "SystemPrompt": "You are a helpful assistant",
      // LLm ModelParams
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\qwen2.5-7b-instruct-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 50,
        "FlashAttention": true,
        "Embeddings": false
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform"
      },
      "ToolPrompt": {
        "Index": 3, // 工具提示配置索引
        "Lang": "zh" //工具提示词语言
      }
    },
    {
      "Name": "llama3.1_8b",
      "Description": "llama3.1 8b Chinese Chat q4_k_m",
      "Version": "3.1",
      "WebSite": "https://huggingface.co/shenzhi-wang/Llama3.1-8B-Chinese-Chat",
      "SystemPrompt": "You are a helpful assistant",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\llama3.1_8b_chinese_chat_q4_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 30
      },
      "AntiPrompts": [ "<|eot_id|>", "<|endoftext|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.LLamaHistoryTransform"
      },
      "ToolPrompt": {
        "Index": 1,
        "Lang": "zh"
      }
    },
    {
      "Name": "qwen2.5_7b",
      "Description": "通义千问 v2.5 7b instruct q5_k_m",
      "Version": "2.5",
      "WebSite": "https://github.com/QwenLM/Qwen2.5",
      // 未指定时使用默认配置
      "SystemPrompt": "You are a helpful assistant",
      // LLm ModelParams
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\qwen2.5-7b-instruct-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 50,
        "FlashAttention": true,
        "Embeddings": false
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform"
      },
      "ToolPrompt": {
        "Index": 2, // 工具提示配置索引
        "Lang": "zh" //工具提示词语言
      }
    },
    {
      "Name": "Phi-3-mini-4k-instruct-q4",
      "Description": "The Phi-3-Mini-4K-Instruct is a 3.8B parameters, lightweight, state-of-the-art open model trained with the Phi-3 datasets that includes both synthetic data and the filtered publicly available websites data with a focus on high-quality and reasoning dense properties.",
      "WebSite": "https://www.modelscope.cn/models/sangsq/Phi-3-mini-4k-instruct-gguf",
      "Version": "2024-07-08",
      "SystemPrompt": "You are a helpful AI assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\Phi-3-mini-4k-instruct-gguf\\Phi-3-mini-4k-instruct-fp16.gguf",
        "ContextSize": 4096,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<|user|>", "<|end|>", "<|endoftext|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.ZephyrHistoryTransform"
      },
      "ToolPrompt": {
        "Index": 0,
        "Lang": "en"
      }
    },
    {
      "Name": "gemma2",
      "Description": "Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.",
      "Version": "2.0",
      "WebSite": "https://huggingface.co/google/gemma-2-9b",
      "SystemPrompt": "You are a helpful assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\gemma2-9b.gguf",
        "ContextSize": 8192,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<start_of_turn>", "<end_of_turn>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.GemmaHistoryTransform"
      }
    },
    {
      "Name": "Llama3-8B-instruct",
      "Description": "Meta Llama 3, a family of models developed by Meta Inc. are new state-of-the-art , available in both 8B and 70B parameter sizes (pre-trained or instruction-tuned).",
      "WebSite": "https://ai.meta.com/blog/meta-llama-3/",
      "Version": "1.0",
      "SystemPrompt": "You are a helpful assistant.",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\llama3.gguf",
        "ContextSize": 8192,
        "Seed": 1337,
        "GpuLayerCount": 20,
        "Embeddings": false
      },
      "AntiPrompts": [ "<|eot_id|>", "<|endoftext|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.LLamaHistoryTransform"
      }
    },
    {
      "Name": "codegemma:7b-instruct_q4",
      "Description": "CodeGemma is a collection of powerful, lightweight models that can perform a variety of coding tasks like fill-in-the-middle code completion, code generation, natural language understanding, mathematical reasoning, and instruction following.",
      "Version": "1.0",
      "WebSite": "https://ollama.com/library/codegemma:7b",
      "SystemPrompt": "You are a helpful, respectful and honest coding assistant.\nAlways reply with using markdown.\nFor code refactoring, use markdown with code formatting.\n  ",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\google\\codegemma.gguf",
        "ContextSize": 4096,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<start_of_turn>", "<end_of_turn>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.GemmaHistoryTransform"
      }
    },
    {
      "Name": "qwen2-1.5b",
      "Description": "通义千问 v2 1.5b Chat q5_k_m",
      "Version": "2",
      "WebSite": "https://github.com/QwenLM/Qwen2",
      "SystemPrompt": "You are a helpful assistant",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\qwen2-1_5b-instruct-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 50,
        "Embeddings": true
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform"
      }
    },
    {
      "Name": "qwen2-0.5b",
      "Description": "通义千问 v2 0.5b Chat q5_k_m",
      "Version": "2",
      "WebSite": "https://github.com/QwenLM/Qwen2",
      "SystemPrompt": "You are a helpful assistant",
      "ModelParams": {
        "ModelPath": "H:\\workspace\\gpt\\models\\qwen2-0_5b-instruct-q5_k_m.gguf",
        "ContextSize": 32768,
        "Seed": 1337,
        "GpuLayerCount": 20
      },
      "AntiPrompts": [ "<|im_start|>", "<|im_end|>" ],
      "WithTransform": {
        "HistoryTransform": "LLamaWorker.Transform.BaseHistoryTransform"
      }
    }
  ],
  "ToolPromptConfig": [
    {
      "PromptConfigDesc": "default",
      "FN_NAME": "Action", // 函数名标识
      "FN_ARGS": "Action Input", // 参数标识
      "FN_RESULT": "Observation", // 结果标识
      "FN_EXIT": "Answer:", // 工具执行后推理标识
      "FN_STOP_WORDS": [ "Observation:", "Answer:" ], // 使用工具时的特殊停止词
      "FN_TEST": "Action:? ?(.*?)\\s*(Action Input:? ?(.*?)\\s*)(?=Observation|$|\\n)", // 函数调提取的正则表达式，用于提取函数名（组1）和参数（组3）
      "FN_CALL_TEMPLATE": "Action: {0}\nAction Input: {1}", // 工具调用填充模板
      "FN_RESULT_SPLIT": "", // 工具调用结果分割标识，在函数调用与结果之间的分割标识
      "FN_RESULT_TEMPLATE": "Observation: {0}", // 工具调用结果填充模板
      "FN_CALL_TEMPLATE_INFO": {
        "zh": "# 工具\n\n## 你拥有如下工具：\n\n{tool_descs}\n",
        "en": "# Tools\n\n## You have access to the following tools:\n\n{tool_descs}\n"
      },
      "FN_CALL_TEMPLATE_FMT": {
        "zh": "## 当你需要调用工具时，请在你的回复中穿插如下的工具调用命令，可以根据需求调用零次或多次：\n\n工具调用\n{0}: 工具名称，必须是[{4}]之一。\n{1}: 工具的输入\n{2}: <result>工具返回的结果</result>\n{3}: 根据Observation总结本次工具调用返回的结果，如果结果中出现url，请使用如下格式展示出来：![图片](url)",
        "en": "## When you need to call a tool, please insert the following command in your reply, You can call zero or more times according to your needs:\n\nTool Invocation\n{0}: The name of the tool, must be one of [{4}]\n{1}: Tool input\n{2}: <result>Tool returns result</result>\n{3}: Summarize the results of this tool call based on Observation. If the result contains url,please display it in the following format:![Image](URL)"
      },
      "FN_CALL_TEMPLATE_FMT_PARA": {
        "zh": "## 当你需要调用工具时，请在你的回复中穿插如下的工具调用命令，可以根据需求调用零次或多次：\n\n工具调用\n{0}: 工具1的名称，必须是[{4}]之一\n{1}: 工具1的输入\n{0}: 工具2的名称，必须是[{4}]之一\n{1}: 工具2的输入\n...\n{0}: 工具N的名称，必须是[{4}]之一\n{1}: 工具N的输入\n{2}: <result>工具1返回的结果</result>\n{2}: <result>工具2返回的结果</result>\n...\n{2}: <result>工具N返回的结果</result>\n{3}: 根据Observation总结本次工具调用返回的结果，如果结果中出现url，请使用如下格式展示出来：![图片](url)",
        "en": "## When you need to call a tool, please intersperse the following tool command in your reply. You can call zero or more times according to your needs:\n\nTool Invocation\n{0}: The name of the tool 1, must be one of [{4}]\n{1}: Tool input to tool 1\n{0}: The name of the tool 2, must be one of [{4}]\n{1}: Tool input to tool 2\n...\n{0}: The name of the tool N, must be one of [{4}]\n{1}: Tool input to tool N\n{2}: <result>Tool 1 returns result</result>\n{2}: <result>Tool 2 returns result</result>\n...\n{2}: <result>Tool N returns result</result>\n{3}: Summarize the results of this tool call based on Observation. If the result contains url,please display it in the following format:![Image](URL)"
      },
      "ToolDescTemplate": {
        "zh": "### {0}\n\n{1}: {2} 输入参数：{3}",
        "en": "### {0}\n\n{1}: {2} Parameters: {3}"
      }
    },
    {
      "PromptConfigDesc": "Llama 模板",
      "FN_NAME": "{\"name\":",
      "FN_ARGS": "\"parameters\":",
      "FN_RESULT": "",
      "FN_EXIT": "<|start_header_id|>assistant<|end_header_id|>",
      "FN_STOP_WORDS": [],
      "FN_TEST": "\\{\"name\" ?: ?\"(.*?)(?:\",)*\\s*(\"parameters\" ?: ?(.*?\"\\s*\\}))(?=\\})",
      "FN_CALL_TEMPLATE": "{{\"name\":\"{0}\", \"parameters\":{1}}}",
      "FN_RESULT_SPLIT": "<|eot_id|>",
      "FN_RESULT_TEMPLATE": "<|start_header_id|>ipython<|end_header_id|>\n{0}<|eot_id|>",
      "FN_CALL_TEMPLATE_INFO": {
        "zh": "你是一个乐于助人的助理，并拥有工具调用能力。当您收到工具调用响应时，使用格式化输出原始问题的答案。\n\n你拥有以下工具，请使用 JSON 格式响应函数调用，并提供最能回答给定提示的正确参数。\n\n{tool_descs}",
        "en": "You are a helpful assistant with tool calling capabilities. When you receive a tool call response, use the output to format an answer to the orginal use question.\n\nGiven the following functions, please respond with a JSON for a function call with its proper arguments that best answers the given prompt.\n\n{tool_descs}"
      },
      "FN_CALL_TEMPLATE_FMT": {
        "zh": "你可以在回复中插入零次、一次或多次以下命令以调用工具：\n\n{0} 工具名称, {1} 工具输入}} 工具名称，必须是[{4}]之一。不要使用变量。",
        "en": "When you need to call a tool, please insert the following command in your reply, which can be called zero or multiple times according to your needs. Respond in the format {0} function name, {1} dictionary of argument name and its value}}. The function name of tool should be one of [{4}]. Do not use variables."
      },
      "FN_CALL_TEMPLATE_FMT_PARA": {
        "zh": "## 你可以在回复中插入以下命令以并行调用N个工具：\n\n{0} 工具1的名称, {1} 工具1的输入}}\n{0} 工具2的名称, {1} 工具2的输入}}\n...\n{0} 工具N的名称, {1} 工具N的输入}} 工具名称，必须是[{4}]之一。不要使用变量。",
        "en": "## Insert the following command in your reply when you need to call N tools in parallel:\n\n{0} The name of tool 1, {1} The input of tool 1}}\n{0}: The name of tool 2, {1} The input of tool 2}}\n...\n{0} The name of tool N, {1} The input of tool N}}. The function name of tool should be one of [{4}]. Do not use variables."
      },
      "ToolDescTemplate": {
        "zh": "{{\"name\": \"{1}\", \"parameters\":{3}}}",
        "en": "{{\"name\": \"{1}\", \"parameters\":{3}}}"
      }
    },
    {
      "PromptConfigDesc": "千问模板",
      "FN_NAME": "✿FUNCTION✿",
      "FN_ARGS": "✿ARGS✿",
      "FN_RESULT": "✿RESULT✿",
      "FN_EXIT": "✿RETURN✿:",
      "FN_STOP_WORDS": [ "✿RESULT✿", "✿RETURN✿" ],
      "FN_TEST": "✿FUNCTION✿:? ?(.*?)\\s*(✿ARGS✿:? ?(.*?)\\s*)(?=✿RESULT✿|$|\\n)",
      "FN_CALL_TEMPLATE": "✿FUNCTION✿: {0}\n✿ARGS✿: {1}",
      "FN_RESULT_SPLIT": "",
      "FN_RESULT_TEMPLATE": "✿RESULT✿: {0}",
      "FN_CALL_TEMPLATE_INFO": {
        "zh": "# 工具\n\n## 你拥有如下工具：\n\n{tool_descs}",
        "en": "# Tools\n\n## You have access to the following tools:\n\n{tool_descs}"
      },
      "FN_CALL_TEMPLATE_FMT": {
        "zh": "## 你可以在回复中插入零次、一次或多次以下命令以调用工具：\n\n{0}: 工具名称，必须是[{4}]之一。\n{1}: 工具输入\n{2}: 工具结果\n{3}: 根据工具结果进行回复，需将图片用![](url)渲染出来",
        "en": "## When you need to call a tool, please insert the following command in your reply, which can be called zero or multiple times according to your needs:\n\n{0}: The tool to use, should be one of [{4}]\n{1}: The input of the tool\n{2}: Tool results\n{3}: Reply based on tool results. Images need to be rendered as ![](url)"
      },
      "FN_CALL_TEMPLATE_FMT_PARA": {
        "zh": "## 你可以在回复中插入以下命令以并行调用N个工具：\n\n{0}: 工具1的名称，必须是[{4}]之一\n{1}: 工具1的输入\n{0}: 工具2的名称\n{1}: 工具2的输入\n...\n{0}: 工具N的名称\n{1}: 工具N的输入\n{2}: 工具1的结果\n{2}: 工具2的结果\n...\n{2}: 工具N的结果\n{3}: 根据工具结果进行回复，需将图片用![](url)渲染出来",
        "en": "## Insert the following command in your reply when you need to call N tools in parallel:\n\n{0}: The name of tool 1, should be one of [{4}]\n{1}: The input of tool 1\n{0}: The name of tool 2\n{1}: The input of tool 2\n...\n{0}: The name of tool N\n{1}: The input of tool N\n{2}: The result of tool 1\n{2}: The result of tool 2\n...\n{2}: The result of tool N\n{3}: Reply based on tool results. Images need to be rendered as ![](url)"
      },
      "ToolDescTemplate": {
        "zh": "### {0}\n\n{1}: {2} 输入参数：{3}",
        "en": "### {0}\n\n{1}: {2} Parameters: {3}"
      }
    },
    {
      "PromptConfigDesc": "千问2.5模板",
      "FN_NAME": "✿FUNCTION✿",
      "FN_ARGS": "✿ARGS✿",
      "FN_RESULT": "✿RESULT✿",
      "FN_EXIT": "✿RETURN✿:",
      "FN_STOP_WORDS": [ "✿RESULT✿", "✿RETURN✿" ],
      "FN_TEST": "✿FUNCTION✿:? ?(.*?)\\s*(✿ARGS✿:? ?(.*?)\\s*)(?=✿RESULT✿|$|\\n)",
      "FN_CALL_TEMPLATE": "✿FUNCTION✿: {0}\n✿ARGS✿: {1}",
      "FN_RESULT_SPLIT": "",
      "FN_RESULT_TEMPLATE": "✿RESULT✿: {0}",
      "FN_CALL_TEMPLATE_INFO": {
        "zh": "# 工具\n\n你可以调用一个或多个函数来协助处理用户完的请求。\n\n你可以在 <tools></tools> XML 标签内找到函数签名：\n<tools>\n{tool_descs}\n</tools>",
        "en": "# Tools\n\nYou may call one or more functions to assist with the user query.\n\nYou are provided with function signatures within <tools></tools> XML tags:\n<tools>\n{tool_descs}\n</tools>"
      },
      "FN_CALL_TEMPLATE_FMT": {
        "zh": "## 你可以在回复中插入零次、一次或多次以下命令以调用工具：\n\n{0}: 工具名称，必须是[{4}]之一。\n{1}: 工具输入\n{2}: 工具结果\n{3}: 根据工具结果进行回复，需将图片用![](url)渲染出来",
        "en": "## When you need to call a tool, please insert the following command in your reply, which can be called zero or multiple times according to your needs:\n\n{0}: The tool to use, should be one of [{4}]\n{1}: The input of the tool\n{2}: Tool results\n{3}: Reply based on tool results. Images need to be rendered as ![](url)"
      },
      "FN_CALL_TEMPLATE_FMT_PARA": {
        "zh": "## 你可以在回复中插入以下命令以并行调用N个工具：\n\n{0}: 工具1的名称，必须是[{4}]之一\n{1}: 工具1的输入\n{0}: 工具2的名称\n{1}: 工具2的输入\n...\n{0}: 工具N的名称\n{1}: 工具N的输入\n{2}: 工具1的结果\n{2}: 工具2的结果\n...\n{2}: 工具N的结果\n{3}: 根据工具结果进行回复，需将图片用![](url)渲染出来",
        "en": "## Insert the following command in your reply when you need to call N tools in parallel:\n\n{0}: The name of tool 1, should be one of [{4}]\n{1}: The input of tool 1\n{0}: The name of tool 2\n{1}: The input of tool 2\n...\n{0}: The name of tool N\n{1}: The input of tool N\n{2}: The result of tool 1\n{2}: The result of tool 2\n...\n{2}: The result of tool N\n{3}: Reply based on tool results. Images need to be rendered as ![](url)"
      },
      "ToolDescTemplate": {
        "zh": "",
        "en": ""
      }
    }
  ],
  // 独立 embedding 服务配置
  "EmbedingForward": "http://127.0.0.1:5000/embeddings"
}
